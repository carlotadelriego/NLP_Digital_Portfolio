{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old.\n",
      "Question 1: Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\n",
      "Question 2: The president of the USA, Donald Trump, is 190 centimeters high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-February 2025.\n",
      "Question 3: The president of the usa, Donald_Trump, is 190 centimeters high and 78 years old. Forbes_Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-february 2025.\n",
      "The president of the USA DonaldTrump is  centimeters high and  years old ForbesMagazine has assessed his wealth currently estimating it at five point five billion as of midFebruary \n",
      "Question. 4: ['The', 'president', 'of', 'the', 'USA', 'DonaldTrump', 'is', 'centimeters', 'high', 'and', 'years', 'old', 'ForbesMagazine', 'has', 'assessed', 'his', 'wealth', 'currently', 'estimating', 'it', 'at', 'five', 'point', 'five', 'billion', 'as', 'of', 'midFebruary']\n",
      "Question 5: president usa, Donald_Trump, 190 centimeters high 78 years old. Forbes_Magazine assessed wealth, currently estimating five point five billion mid-february 2025.\n",
      "Question 6: ('The', 'president')\n",
      "Question 6: ('president', 'of')\n",
      "Question 6: ('of', 'the')\n",
      "Question 6: ('the', 'USA')\n",
      "Question 6: ('USA', 'Donald_Trump')\n",
      "Question 6: ('Donald_Trump', 'is')\n",
      "Question 6: ('is', '190')\n",
      "Question 6: ('190', 'centimeters')\n",
      "Question 6: ('centimeters', 'high')\n",
      "Question 6: ('high', 'and')\n",
      "Question 6: ('and', '78')\n",
      "Question 6: ('78', 'years')\n",
      "Question 6: ('years', 'old')\n",
      "Question 6: ('old', 'Forbes_Magazine')\n",
      "Question 6: ('Forbes_Magazine', 'has')\n",
      "Question 6: ('has', 'assessed')\n",
      "Question 6: ('assessed', 'his')\n",
      "Question 6: ('his', 'wealth')\n",
      "Question 6: ('wealth', 'currently')\n",
      "Question 6: ('currently', 'estimating')\n",
      "Question 6: ('estimating', 'it')\n",
      "Question 6: ('it', 'at')\n",
      "Question 6: ('at', 'five')\n",
      "Question 6: ('five', 'point')\n",
      "Question 6: ('point', 'five')\n",
      "Question 6: ('five', 'billion')\n",
      "Question 6: ('billion', 'as')\n",
      "Question 6: ('as', 'of')\n",
      "Question 6: ('of', 'mid')\n",
      "Question 6: ('mid', 'February')\n",
      "Question 6: ('February', '2025')\n",
      "Question 7: The next word after 'currently' is 'estimating'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/carlotafernandez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/carlotafernandez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For the next text, perform the following actions\n",
    "text = \"The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\"\n",
    "\n",
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# First I split the text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    print(\"Question 1:\", sentence)\n",
    "\n",
    "\n",
    "\n",
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n",
    "import re\n",
    "\n",
    "#Convert U.S.A. to USA\n",
    "text = re.sub(r'U.S.A.', 'USA', text)\n",
    "\n",
    "#Convert 1.9m to 190 centimeters\n",
    "text = re.sub(r'1.9m', '190 centimeters', text)\n",
    "\n",
    "#Convert $5.5 billion to five point five billion\n",
    "text = re.sub(r'\\$5.5 billion', 'five point five billion', text)\n",
    "\n",
    "print(\"Question 2:\", text)\n",
    "\n",
    "\n",
    "\n",
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fernández -> Juan_Fernández).\n",
    "# Convert multiword proper names to single words with underscores\n",
    "def replace_proper_names(match):\n",
    "    return match.group(0).replace(\" \", \"_\")\n",
    "\n",
    "text = re.sub(r'\\b(Donald Trump|Forbes Magazine|United States of America)\\b', replace_proper_names, text)\n",
    "\n",
    "# Convert text to lowercase except for proper nouns\n",
    "def convert_proper_nouns(text):\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "\n",
    "    # Process each word\n",
    "    for i, word in enumerate(words):\n",
    "        if \"_\" in word or (i == 0 and word.istitle()):\n",
    "            processed_words.append(word)\n",
    "        else:\n",
    "            processed_words.append(word.lower())\n",
    "\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "converted_text = convert_proper_nouns(text)\n",
    "print(\"Question 3:\", converted_text)\n",
    "\n",
    "\n",
    "\n",
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "# Remove special characters\n",
    "pure_clean = re.sub(r'[^a-zA-Z\\s]', '', text)  # Pure Python\n",
    "print(pure_clean)\n",
    "nltk_tokens = nltk.word_tokenize(pure_clean)\n",
    "print(\"Question. 4:\", nltk_tokens)\n",
    "\n",
    "\n",
    "\n",
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer). \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Divide the text into words and process them\n",
    "words = text.split()\n",
    "processed_words = [(word if \"_\" in word or word.istitle() else word.lower()) for word in words] \n",
    "\n",
    "# Remove stopwords from the text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = ' '.join([word for word in processed_words if word.lower() not in stop_words]) \n",
    "print(\"Question 5:\", filtered_text)\n",
    "\n",
    "\n",
    "\n",
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "# Tokenize the text into words (splitting by whitespace and punctuation)\n",
    "words = re.findall(r'\\b\\w+\\b', text)\n",
    "bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n",
    "for bigram in bigrams:\n",
    "    print(\"Question 6:\", bigram)\n",
    "    \n",
    "\n",
    "\n",
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n",
    "# Create a dictionary of bigram frequencies\n",
    "bigram_freq = {}\n",
    "for i in range(len(words) - 1):\n",
    "    if words[i] not in bigram_freq:\n",
    "        bigram_freq[words[i]] = {} # if the word is not in the dictionary add it with an empty dictionary as its value\n",
    "\n",
    "    if words[i + 1] not in bigram_freq[words[i]]:\n",
    "        bigram_freq[words[i]][words[i + 1]] = 0 # if the next word is not in the dictionary add it with a frequency of 0\n",
    "    bigram_freq[words[i]][words[i + 1]] += 1 # if the next word is in the dictionary increment its frequency by 1\n",
    "\n",
    "\n",
    "# Function to predict the next word given a current word\n",
    "def predict_next_word(current_word):\n",
    "    if current_word in bigram_freq:\n",
    "        return max(bigram_freq[current_word], key=bigram_freq[current_word].get)\n",
    "    return None\n",
    "\n",
    "# Example of using the function\n",
    "current_word = \"currently\"\n",
    "next_word = predict_next_word(current_word)\n",
    "print(f\"Question 7: The next word after '{current_word}' is '{next_word}'\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
