{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMoADcrhJP2H"
   },
   "source": [
    "## Bag of Words\n",
    "\n",
    "In the last notebook, we saw how to get the one hot encoding representation for our toy corpus. In this notebook we will see how to use bag of words representation for the same data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.21.3\n",
      "  Using cached scikit-learn-0.21.3.tar.gz (12.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages (from scikit-learn==0.21.3) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages (from scikit-learn==0.21.3) (1.13.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages (from scikit-learn==0.21.3) (1.4.2)\n",
      "Building wheels for collected packages: scikit-learn\n",
      "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[49 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  \u001b[31m   \u001b[0m   from pkg_resources import parse_version\n",
      "  \u001b[31m   \u001b[0m Partial import of sklearn during the build process.\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/setup.py:122: DeprecationWarning:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "  \u001b[31m   \u001b[0m   of the deprecation of `distutils` itself. It will be removed for\n",
      "  \u001b[31m   \u001b[0m   Python >= 3.12. For older Python versions it will remain present.\n",
      "  \u001b[31m   \u001b[0m   It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "  \u001b[31m   \u001b[0m   For more details, see:\n",
      "  \u001b[31m   \u001b[0m     https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   from numpy.distutils.command.build_ext import build_ext  # noqa\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/setup.py\", line 290, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup_package()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/setup.py\", line 286, in setup_package\n",
      "  \u001b[31m   \u001b[0m     setup(**metadata)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/core.py\", line 136, in setup\n",
      "  \u001b[31m   \u001b[0m     config = configuration()\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/setup.py\", line 174, in configuration\n",
      "  \u001b[31m   \u001b[0m     config.add_subpackage('sklearn')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 1050, in add_subpackage\n",
      "  \u001b[31m   \u001b[0m     config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "  \u001b[31m   \u001b[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 1016, in get_subpackage\n",
      "  \u001b[31m   \u001b[0m     config = self._get_configuration_from_setup_py(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "  \u001b[31m   \u001b[0m     config = setup_module.configuration(*args)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/sklearn/setup.py\", line 62, in configuration\n",
      "  \u001b[31m   \u001b[0m     config.add_subpackage('utils')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 1050, in add_subpackage\n",
      "  \u001b[31m   \u001b[0m     config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "  \u001b[31m   \u001b[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 1016, in get_subpackage\n",
      "  \u001b[31m   \u001b[0m     config = self._get_configuration_from_setup_py(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/miniconda3/envs/uie-aa/lib/python3.11/site-packages/numpy/distutils/misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "  \u001b[31m   \u001b[0m     config = setup_module.configuration(*args)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/2s/7v3f02n56pl_2xqtzwjzqq_h0000gn/T/pip-install-2bu32fjc/scikit-learn_83ff5a24bd254899957b82fbac2e20eb/sklearn/utils/setup.py\", line 8, in configuration\n",
      "  \u001b[31m   \u001b[0m     from Cython import Tempita\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'Cython'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for scikit-learn\n",
      "Failed to build scikit-learn\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (scikit-learn)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
    "\n",
    "# ===========================\n",
    "\n",
    "!pip install scikit-learn==0.21.3\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'ch3-requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
    "\n",
    "# ===========================\n",
    "\n",
    "try :\n",
    "    import google.colab\n",
    "    !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
    "except ModuleNotFoundError :\n",
    "    !pip install -r \"ch3-requirements.txt\"\n",
    "\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mhnX4sORJP2J",
    "outputId": "30c24110-5f13-4b02-e8ff-e5856f355dd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"] #Same as the earlier notebook\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEm3kuokJP2N"
   },
   "source": [
    "Now, let's do the main task of finding bag of words representation. We will use CountVectorizer from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "pbCdQVWQJP2O",
    "outputId": "ab104c9f-49b3-432b-ea5b-c13413f3b8b7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our corpus:  ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n",
      "BoW representation for 'man bites dog:  [[1 1 0 0 1 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#look at the documents list\n",
    "print(\"Our corpus: \", processed_docs)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we represented the text considering the frequency of words into account. However, sometimes, we don't care about frequency much, but only want to know whether a word appeared in a text or not. That is, each document is represented as a vector of 0s and 1s. We will use the option binary=True in CountVectorizer for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bvFoqDRAJP2Q",
    "outputId": "919d12a0-597d-45ae-ef73-251a87629a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow representation for 'dog and dog are friends': [[0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#BoW with binary vectors\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "count_vect.fit(processed_docs)\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see how we can use BoW representation for Text Classification later in Chapter 4. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bag of Words, N-Grams and TF-IDF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
